---
title: "Week2 - BasicStatistics "
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Basic Statistics
This week we'll be diving into some basic statistical procedures. R started out as THE statistical programming language. It spread like wildfire for it's performance and efficiency at crunching numbers. It's early success as a statistical programming langugae attracted the early developers who really made R into the do-it-all language we're using today. First, I'll throw in the useful definitions list at the top of this tutorial just for ease of access. Second, we'll dive into a recap of for loops and how they're structured. Then we'll show off some of R's great statistics functions and how to add them to a plot. Finally, we'll have an assignment where we cover some of 

## Some Useful Definitions

| Function                 |             Description        |
| -----------| -------------------------------------------- |
| ls | lists contents of R workspace/global environment | 
| rm | removes objects from R workspace | 
| save|  save selected objects |
| +,-,*,/,^ | arithmetic operators | 
| %*% |  matrix multiplication |
| t | matrix transpose | 
| solve | matrix inverse (and solving linear equations) | 
| c | combines (concatenates) objects, simplest way to make vectors | 
| seq | creates vectors that are regular sequences | 
| rep | replicates vectors | 
| length| returns length of a vector | 
| sum | returns the sum |
| mean | returns the mean | 
| median | returns the median | 
| sd | returns the standard deviation (n − 1 in denominator) | 
| min | returns minimum | 
| max | returns maximum |
| sort | sort a vector (rearranges the vector in order) |
| order | returns indices of vectors that will order them |
| rank | returns rank of each element in vector | 
| ==, <, > | comparison operators |
| <=, >=, != | |
| |, & | OR, AND |
| is.na | tests for missing value NA | 
|which |does logical comparison and indicates which elements are TRUE that is, gives the TRUE indices of a logical object|
| any |does logical comparison returns 1 (TRUE) if any of the comparisons are TRUE, i.e. is at least one of the values true? |
|exp |returns e to that power|
|log |returns natural logarithm (to the base e)|
|log10| returns logarithm (to the base 10)|
|sqrt| returns square root|
|table |does frequencies and cross-tabs|
|help |help page on specified function|
|cbind |combine by columns|
|rbind |combine by rows|
|matrix| create a matrix|
|vector |create a vector|
|nrow| number of rows in an array or data frame|
|ncol |number of columns in an array or data frame|
|dim| dimensions of an array or data frame|
|array| create an array|

| Function                 |             Description        |
| -----------| -------------------------------------------- |
|is.vector |answers the question, is this a vector TRUE or FALSE|
|as.vector |attempts to coerce object into a vector|
|read.table |reads data from a text file|
|read.csv |reads data from a text file with comma separated data|
|write.table| writes a data frame to a text file|
|is.data.frame| tests object to see if it is data frame|
|as.data.frame |coerces object into data frame|
|is.factor |tests object to see if it is a factor|
|as.factor |coerces object into a factor|
|head, tail |list the first, last six rows|
|names |returns names of elements of object|
|colnames| returns or sets column names of object|
|rownames |returns or sets row names of object|
|subset| select part of a vector, matrix, or data frame|
|merge |merge two data frames|
|lm |multiple linear regression|
|glm |generalized linear regression|
|anova |analysis of variance|
|chisq.test |Pearson’s Chi-squared test for count data|
|summary| shows results of various model fitting functions|
|predict |predicted results from model|
|hist| histogram|
|boxplot| box plot|
|plot |scatterplot|
|lines |connects points sequentially with lines (added to a plot)|
|segments| add lines to a plot (between pairs of points)|
|text |add text to a plot|
|legend |add a legend to a plot|
|abline |add a line to a plot by specifying its slope and intercept|
|passing |an lm object will result in adding the predicted line to the plot|
|x11 |open another graphics window (PC)|
|pdf |open a pdf file for recording graphics|
|dev.off| close graphics device|
|par(mfrow) |arranges multiple plots on same page (by row)|
|sample |produces a random sample of the specified values|
|set.seed |sets seed for next random sample (repeat random sample)|
|rnorm |produces a random sample from a normal distribution|
|qnorm |quantiles (percentiles) of normal distribution|
|pnorm |CDF of normal distribution|
|dnorm |PDF of normal distribution|
|rbinom |produces a random sample from a binomial distribution|

# Basic Statistics in R

R is famous for it's easy-to-use statistics features and once you get the hang of it you'll never want to touch Microsoft Excel again. Despite the fact that these stats functions seem pretty fancy to me, I call them basic functions because R has so much to offer to statisticians. We'll be using multiple meteorological / climate model datasets for this tutorial. Let's get started with some of these functions...

### Load the data
```{r}
library(ncdf4)
# open the netcdf file of Willow Creek, Wisconsin meteorology data
nc_file = nc_open("/Users/james/Documents/Github/geog473-673/datasets/WCr_1hr.2010.nc")
# what does the nc file look like 
nc_file
# ok, still a lot of info...let's list the names of the variables
names(nc_file$var)
# alright, now we have some names, so let's put the variables into a new dataframe separate from the nc_file
var_names = names(nc_file$var)
willow_creek_2010 = list()
dim <- nc_file$dim
for (v in seq_along(var_names)){
  willow_creek_2010[[v]] = ncvar_get(nc_file, varid = var_names[v])
}
# convert the list into a dataframe
wcreek_df = data.frame(willow_creek_2010)
# tell the dataframe what the column names are
colnames(wcreek_df) = var_names
# print some summary stats of wcreek_df
summary(wcreek_df)
# ok, so we see the units and values
dim$time$units
dim$time$vals[1:10]
# so without any extra metadata, we can back out that this data is hourly data just from the units being seconds and time between
# each recorded value (3600 seconds == 1 hour)
#### Add a datetime column ####
date.seq = seq(as.POSIXct("2010-01-01 00:00:00"), as.POSIXct("2010-12-31 23:00:00"), by="hour")
wcreek_df['datetime'] = date.seq
summary(wcreek_df)
```

The data is loaded, organized, and ready for statistical analysis. Let's take a look at air temperature in relation to season. We're going to look at temperatures during the first half of the year by indexing air temperature and date from the 1st index to half the length of the dataset `[1:length(wcreek_df$datetime) / 2]` . So instead of having 8760 temperature values (there's 8760 hours in a non leap-year), we only have 4380. 

```{r}
plot(wcreek_df$air_temperature[1:length(wcreek_df$air_temperature) / 2] ~ wcreek_df$datetime[1:length(wcreek_df$datetime) / 2], pch = 20, col="blue")

# alright, so yeah we know in the northern hemisphere that temperature increases between winter and summer months...but what is the trend like?
fit <- lm(air_temperature[1:length(wcreek_df$air_temperature) / 2] ~ wcreek_df$datetime[1:length(wcreek_df$datetime) / 2], data = wcreek_df)
summary(fit)
coef(fit)

# set our indexes
start_ind = 1
end_ind = length(wcreek_df$air_temperature) / 2 # calculate the length of the data and divide it by 2 to get the first half of year

plot(air_temperature[start_ind:end_ind] ~ wcreek_df$datetime[start_ind:end_ind], data = wcreek_df,
  main= "air_temperature vs. datetime",
  ylab= "Air Temperature ( Kelvin )",
  xlab= "Datetime",
  pch= 19, col= 'blue')
grid(NA,NULL, lty= 4) # NA first for no y axis grid lines, null second to ignore the default x axis linetype
abline(fit, col= 'black', lty= 4, lwd= 2)
legend("topleft", legend=c("lm(fit)"), col= 2, lty= 4, bg= "gray85", box.lty=0)
```

So that's how you would go about investigating trendlines. Histograms are a good way to check out the distribution of data. Let's do that and add in a basic trendline for the probability distribution.

Let's add this to a histogram of the data
```{r}
hist(wcreek_df$air_temperature[1:length(wcreek_df$air_temperature) / 2], freq = FALSE)
x <- seq(250, 310, length.out=100)
y <- with(wcreek_df, dnorm(x, mean(air_temperature[start_ind:end_ind]), 
          sd(air_temperature[start_ind:end_ind])))
lines(x, y, col = "red")
```

Density plots can be thought of as plots of smoothed histograms. The smoothness is controlled by a bandwidth parameter that is analogous to the histogram binwidth.  Let's plot up the density of all the temperature values within this half of the data.

```{r}
d = density(wcreek_df$air_temperature[start_ind:end_ind], bw = 0.5)
plot(d, xlab = "Air Temperature (Kelvin)", ylab = "Density", main="Air Temperature Density", col="black")
```

For a moderate number of observations a useful addition is a jittered rug plot:

```{r}
plot(density(wcreek_df$air_temperature[start_ind:end_ind], bw = 0.5), main = "jittered rug plot")
rug(jitter(wcreek_df$air_temperature[start_ind:end_ind]))
```

### Correlation Plots

Correlation plots show correlation coefficients across variables. For example, we expect shortwave radiation and temperature to have high a high correlation coefficient because generally speaking when the a lot of sunlight is received at the surface, temperature increases. There's a handy package called `corrplot` that caluclates correlation coefficients quickly and intuitively. We'll need to install this package and run our dataframe through it. One last thing...we'll need to calculate the residual values - that is the distance between actual data and the trendline. It's another way to express error. Let's reload a Willow Creek dataset.

```{r, fig.width=10, fig.height=10}
library(corrplot)
library(lubridate) # might need to install lubridate
library(ncdf4)
y = 2010
nc_file = nc_open(paste0("/Users/james/Documents/Github/geog473-673/datasets/WCr_1hr.", y,".nc"))
# what does the nc file look like 
var_names = names(nc_file$var)
wcr_data = list()
dim <- nc_file$dim
for (v in seq_along(var_names)){
  wcr_data[[v]] = ncvar_get(nc_file, varid = var_names[v])
}
wcreek_df = data.frame(wcr_data)
colnames(wcreek_df) = var_names

date.seq = seq(as.POSIXct(paste0(y,"-01-01 00:00:00")), as.POSIXct(paste0(y,"-12-31 23:00:00")), by="hour")
# everything is the same as before, but HERE is where things change a little...
# instead of plugging in the datetimes into the data frame, we need to plug in a numeric. Since a datetime
# is a "POSIXct" class, the correlation matrix function won't know how to handle it. We need a NUMERIC value for this.
# for now, let's just choose our "date" label to be in the form of day-of-year
days = yday(date.seq) # use lubridates yday function, returns a NUMERIC value
wcreek_df['day_of_year'] = days
summary(wcreek_df)

# awesome, now let's calculate the correlation coefficients
cor_wcreek = cor(wcreek_df)
head(cor_wcreek)
# now let's calculate the residuals of the correlations with a 95% confidence interval
residuals_1 <- cor.mtest(wcreek_df, conf.level = .95)
# now let's plot this up. 
corrplot(cor_wcreek, p.mat = residuals_1$p, method = 'color', number.cex = .7, type = 'lower',
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "black", tl.srt = 90, # Text label color and rotation
         # Combine with significance
         sig.level = 0.05, insig = "blank")
```



# Week 2 Assignment:


Using the WCr_1hr.2010.nc, WCr_1hr.2011.nc and WCr_1hr.2012.nc found in the datasets folder, complete the following:

1. Make a **3 column plot** (each year gets 1 plot) of `surface_downwelling_shortwave_flux_in_air` (radiation from the sun) showing the data and trendlines for each year for the **second half** of the year (~ July 1 to Dec 31)
- Note that it's alright if the abline goes outside of the plot, I'll show you how to fix this later
2. Using the data and same time range above, make a **3 row plot** showing the jittered rug plot with 0.75 bandwidth for each year of `surface_downwelling_shortwave_flux_in_air`
3. Submit plots to assignment 2 on canvas


Your final plots should look something like this **but with different colors**

```{r, echo=FALSE,fig.width=8, fig.height=6}
library(plotrix)
par(mfrow=c(1,3)) ## create plot array of 1 row x 3columns
year.seq = seq(2010,2012,1)
for (y in year.seq){
  nc_file = nc_open(paste0("/Users/james/Documents/Github/geog473-673/datasets/WCr_1hr.", y,".nc"))
  # what does the nc file look like 
  var_names = names(nc_file$var)
  wcr_data = list()
  dim <- nc_file$dim
  for (v in seq_along(var_names)){
    wcr_data[[v]] = ncvar_get(nc_file, varid = var_names[v])
  }
  wcreek_df = data.frame(wcr_data)
  colnames(wcreek_df) = var_names

  date.seq = seq(as.POSIXct(paste0(y,"-01-01 00:00:00")), as.POSIXct(paste0(y,"-12-31 23:00:00")), by="hour")
  wcreek_df['datetime'] = date.seq
  
  fit <- lm(wcreek_df$surface_downwelling_shortwave_flux_in_air[4380:length(wcreek_df$surface_downwelling_shortwave_flux_in_air)] ~ wcreek_df$datetime[4380:length(wcreek_df$datetime)], data = wcreek_df)
  summary(fit)
  coef(fit)
  
  plot(surface_downwelling_shortwave_flux_in_air[4380:length(wcreek_df$surface_downwelling_shortwave_flux_in_air)] ~ datetime[4380:length(wcreek_df$datetime)], data = wcreek_df,
    main= paste0("shortwave radiation vs. datetime ", y),
    ylab= "Radiation ( W m-2 )",
    xlab= "Datetime",
    pch= 19, col= 'blue')
  grid(NA,NULL, lty= 4) # NA first for no y axis grid lines, null second to ignore the default x axis linetype
  ablineclip(fit,y1=0, col= 'coral', lty= 4, lwd= 6)
  legend("topleft", legend=c("lm(fit)"), col= "dodgerblue", lty= 4, bg= "gray85", box.lty=0)
}
```
```{r, echo=FALSE,fig.width=6, fig.height=10}
par(mfrow=c(3,1)) ## create plot array of 1 row x 3columns
year.seq = seq(2010,2012,1)
for (y in year.seq){
  nc_file = nc_open(paste0("/Users/james/Documents/Github/geog473-673/datasets/WCr_1hr.", y,".nc"))
  # what does the nc file look like 
  var_names = names(nc_file$var)
  wcr_data = list()
  dim <- nc_file$dim
  for (v in seq_along(var_names)){
    wcr_data[[v]] = ncvar_get(nc_file, varid = var_names[v])
  }
  wcreek_df = data.frame(wcr_data)
  colnames(wcreek_df) = var_names

  date.seq = seq(as.POSIXct(paste0(y,"-01-01 00:00:00")), as.POSIXct(paste0(y,"-12-31 23:00:00")), by="hour")
  wcreek_df['datetime'] = date.seq
  
  fit <- lm(wcreek_df$air_pressure[4380:length(wcreek_df$air_pressure)] ~ wcreek_df$datetime[4380:length(wcreek_df$datetime)], data = wcreek_df)
  summary(fit)
  coef(fit)
  
  plot(density(wcreek_df$air_pressure[4380:length(wcreek_df$air_pressure)], bw = 0.25),
       main = paste0("shortwave radiation density jittered rugplot ", y), lwd=2, col="red")
  rug(jitter(wcreek_df$air_pressure[4380:length(wcreek_df$air_pressure)]))
}
```


## Extra Credit - 2 points

Using the WCr_1hr.2010.nc, WCr_1hr.2011.nc and WCr_1hr.2012.nc found in the datasets folder, complete the following

1) Fuse together the 3 datasets into one continuous dataframe.
2) Resample the data from an hourly to a daily resolution
3) Plot Air temperature for your new combined data frame and add a trendline to it.
4) Submit to assignment above labeled 'extra_credit.png'

